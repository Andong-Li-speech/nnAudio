{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from librosa.core import note_to_hz\n",
    "from scipy.signal import get_window\n",
    "from scipy import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = np.load('y_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fourier_kernals(n_fft, freq_bins=None, low=50,high=6000, sr=44100, freq_scale='linear', window='hann'):\n",
    "    \"\"\"\n",
    "    If freq_scale is 'no', then low and high arguments will be ignored\n",
    "    \"\"\"\n",
    "    if freq_bins==None:\n",
    "        freq_bins = n_fft//2+1\n",
    "\n",
    "    s = np.arange(0, n_fft, 1.)\n",
    "    wsin = np.empty((freq_bins,1,n_fft))\n",
    "    wcos = np.empty((freq_bins,1,n_fft))\n",
    "    start_freq = low\n",
    "    end_freq = high\n",
    "\n",
    "\n",
    "    # num_cycles = start_freq*d/44000.\n",
    "    # scaling_ind = np.log(end_freq/start_freq)/k\n",
    "\n",
    "    # Choosing window shape\n",
    "\n",
    "    window_mask = get_window(window,int(n_fft), fftbins=True)\n",
    "\n",
    "\n",
    "    if freq_scale == 'linear':\n",
    "        start_bin = start_freq*n_fft/sr\n",
    "        scaling_ind = (end_freq/start_freq)/freq_bins\n",
    "        for k in range(freq_bins): # Only half of the bins contain useful info\n",
    "            wsin[k,0,:] = window_mask*np.sin(2*np.pi*(k*scaling_ind*start_bin)*s/n_fft)\n",
    "            wcos[k,0,:] = window_mask*np.cos(2*np.pi*(k*scaling_ind*start_bin)*s/n_fft)\n",
    "    elif freq_scale == 'log':\n",
    "        start_bin = start_freq*n_fft/sr\n",
    "        scaling_ind = np.log(end_freq/start_freq)/freq_bins\n",
    "        for k in range(freq_bins): # Only half of the bins contain useful info\n",
    "            wsin[k,0,:] = window_mask*np.sin(2*np.pi*(np.exp(k*scaling_ind)*start_bin)*s/n_fft)\n",
    "            wcos[k,0,:] = window_mask*np.cos(2*np.pi*(np.exp(k*scaling_ind)*start_bin)*s/n_fft)\n",
    "    elif freq_scale == 'no':\n",
    "        for k in range(freq_bins): # Only half of the bins contain useful info\n",
    "            wsin[k,0,:] = window_mask*np.sin(2*np.pi*k*s/n_fft)\n",
    "            wcos[k,0,:] = window_mask*np.cos(2*np.pi*k*s/n_fft)\n",
    "    else:\n",
    "        print(\"Please select the correct frequency scale, 'linear' or 'log'\")\n",
    "    return wsin.astype(np.float32),wcos.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(x, thersold):\n",
    "    x[x<thersold] = 0\n",
    "    indices = torch.nonzero(x).t()\n",
    "    values = x[indices[0], indices[1]]\n",
    "    x_sparse = torch.sparse.FloatTensor(indices, values, x.size())\n",
    "    return x_sparse\n",
    "\n",
    "def nextpow2(A):\n",
    "    return int(np.ceil(np.log2(A)))\n",
    "\n",
    "def create_cqt_kernals(fs, fmin, fmax=None, n_bins=84, bins_per_octave=12, norm=1, window='hann'):\n",
    "    # norm arg is not functioning\n",
    "    \n",
    "    Q = 1/(2**(1/bins_per_octave)-1)\n",
    "    fftLen = 2**nextpow2(np.ceil(Q * fs / fmin))\n",
    "    # minWin = 2**nextpow2(np.ceil(Q * fs / fmax))\n",
    "    if (fmax != None) and  (n_bins == None):\n",
    "        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin)) # Calculate the number of bins\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))    \n",
    "    elif (fmax == None) and  (n_bins != None):\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "    else:\n",
    "        warnings.warn('If fmax is given, n_bins will be ignored',SyntaxWarning)\n",
    "        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin)) # Calculate the number of bins\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "\n",
    "    tempKernel = np.zeros((int(n_bins), int(fftLen)), dtype=np.complex64)\n",
    "    specKernel = np.zeros((int(n_bins), int(fftLen)), dtype=np.complex64)    \n",
    "    for k in range(0, int(n_bins)):\n",
    "        freq = freqs[k]\n",
    "        l = np.ceil(Q * fs / freq)\n",
    "        lenghts = np.ceil(Q * fs / freqs)\n",
    "        # Centering the kernals\n",
    "        if l%2==1: # pad more zeros on RHS\n",
    "            start = int(np.ceil(fftLen / 2.0 - l / 2.0))-1\n",
    "        else:\n",
    "            start = int(np.ceil(fftLen / 2.0 - l / 2.0))\n",
    "        sig = get_window(window,int(l), fftbins=True)*np.exp(np.r_[-l//2:l//2]*1j*2*np.pi*freq/fs)/l\n",
    "#         if norm: # Normalizing the filter # Trying to normalize like librosa\n",
    "#             tempKernel[k, start:start + int(l)] = sig/np.linalg.norm(sig, norm)\n",
    "#         else:\n",
    "        tempKernel[k, start:start + int(l)] = sig\n",
    "        # specKernel[k, :]=fft(conj(tempKernel[k, :]))\n",
    "        specKernel[k, :] = fft(tempKernel[k])\n",
    "        \n",
    "    return specKernel[:,:fftLen//2+1], fftLen, torch.tensor(lenghts).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CQT1992(torch.nn.Module):\n",
    "    def __init__(self, sr=22050, hop_length=512, fmin=220, fmax=None, n_bins=84, bins_per_octave=12, norm=1, window='hann', center=False, pad_mode='reflect'):\n",
    "        super(CQT1992, self).__init__()\n",
    "        # norm arg is not functioning\n",
    "        \n",
    "        self.hop_length = hop_length\n",
    "        self.center = center\n",
    "        self.pad_mode = pad_mode\n",
    "        self.norm = norm\n",
    "        \n",
    "        # creating kernals for CQT\n",
    "        self.cqt_kernals, self.kernal_width, lenghts = create_cqt_kernals(sr, fmin, fmax, n_bins, bins_per_octave, norm, window)\n",
    "        print(\"done CQT filter\")\n",
    "        self.cqt_kernals_real = torch.tensor(self.cqt_kernals.real)\n",
    "        self.cqt_kernals_imag = torch.tensor(self.cqt_kernals.imag)\n",
    "        print(\"done CQT to torch tensor\")\n",
    "        self.cqt_kernals_real = to_sparse(self.cqt_kernals_real, 1e-5)\n",
    "        self.cqt_kernals_imag = to_sparse(self.cqt_kernals_imag, 1e-5)\n",
    "        print(\"done to sparse\")\n",
    "        \n",
    "        # creating kernals for stft\n",
    "#         self.cqt_kernals_real*=lenghts.unsqueeze(1)/self.kernal_width # Trying to normalize as librosa\n",
    "#         self.cqt_kernals_imag*=lenghts.unsqueeze(1)/self.kernal_width\n",
    "        wsin, wcos = create_fourier_kernals(self.kernal_width, window='ones', freq_scale='no')\n",
    "        self.wsin = torch.tensor(wsin)\n",
    "        self.wcos = torch.tensor(wcos)  \n",
    "        print(\"done fourier filter\")\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if x.dim() == 2:\n",
    "            x = x[:, None, :]\n",
    "        elif x.dim() == 1:\n",
    "            x = x[None, None, :]\n",
    "        else:\n",
    "            raise ValueError(\"Only support input with shape = (batch, len) or shape = (len)\")\n",
    "        if self.center:\n",
    "            if self.pad_mode == 'constant':\n",
    "                padding = nn.ConstantPad1d(self.kernal_width//2, 0)\n",
    "            elif self.pad_mode == 'reflect':\n",
    "                padding = nn.ReflectionPad1d(self.kernal_width//2)\n",
    "\n",
    "            x = padding(x)\n",
    "\n",
    "        # STFT\n",
    "        fourier_real = conv1d(x, self.wcos, stride=self.hop_length)\n",
    "        fourier_imag = conv1d(x, self.wsin, stride=self.hop_length)\n",
    "        \n",
    "        # CQT\n",
    "        CQT_real, CQT_imag = complex_mul((self.cqt_kernals_real, self.cqt_kernals_imag), \n",
    "                                         (fourier_real, fourier_imag))\n",
    "        \n",
    "        # Getting CQT Amplitude\n",
    "        CQT = torch.sqrt(CQT_real.pow(2)+CQT_imag.pow(2))\n",
    "        \n",
    "        return CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done CQT filter\n",
      "done CQT to torch tensor\n",
      "done to sparse\n",
      "done fourier filter\n",
      "total time used = 50.11716294288635\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "cqt_layer = CQT1992(sr=44100, n_bins=168, bins_per_octave=24, fmin=note_to_hz('A1'))\n",
    "time_used = time.time()-t_start\n",
    "print(\"total time used = {}\".format(time_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
